<!doctype html>
<!--
http://html5.by/blog/audio/
http://webaudiodemos.appspot.com/AudioRecorder/index.html
https://truongtx.me/2014/08/09/record-and-export-audio-video-files-in-browser-using-web-audio-api/
http://www.doboism.com/blog/2013/10/17/web-audio-api-browser-support/
https://github.com/mattdiamond/Recorderjs

http://stackoverflow.com/questions/23924642/best-way-to-send-web-audio-api-stream-to-server-side-java-for-processing
https://github.com/soareschen/web-audio-upload/blob/master/page.html
-->
<html>
    <head>
        <meta name="viewport" content="width=device-width,initial-scale=1">
        <title>Audio Recorder</title>
        <!-- 
                <script src="voiceinput/recorder.js"></script>
                <script src="voiceinput/main.js"></script>
        -->
    <style type="text/css">
        #analyser{
            background-color:gray;
        }
    </style>
    </head>
    <body>

        <canvas id="analyser" width="200" height="40"></canvas>
        <!-- 
        <input type="button" value="Start recording"  onclick="startRecording(this);">
        <input type="button" value="Stop recording"  onclick="stopRecording(this);">
    
        <a id="save" href="#">Save</a>
        -->

        <script type="application/javascript" src="https://code.jquery.com/jquery-2.1.4.min.js"></script>
        <script type="application/javascript">
    
    
            var tutor={inputs:{}};



            $(window).load(function(){
                tutor.inputs.audioapi={};
                

                tutor.inputs.audioapi.updateAnalysers=function (time) {
                    if (!tutor.inputs.audioapi.analyserContext) {
                        var canvas = document.getElementById("analyser");
                        tutor.inputs.audioapi.canvasWidth = canvas.width;
                        tutor.inputs.audioapi.canvasHeight = canvas.height;
                        tutor.inputs.audioapi.analyserContext = canvas.getContext('2d');
                    }

                    // analyzer draw code here
                    {
                        var SPACING = 5;
                        var BAR_WIDTH = 3;
                        var scaleY=0.1;
                        var numBars = Math.round(tutor.inputs.audioapi.canvasWidth / SPACING);
                        var freqByteData = new Uint8Array(tutor.inputs.audioapi.analyserNode.frequencyBinCount);

                        tutor.inputs.audioapi.analyserNode.getByteFrequencyData(freqByteData); 

                        tutor.inputs.audioapi.analyserContext.clearRect(0, 0, tutor.inputs.audioapi.canvasWidth, tutor.inputs.audioapi.canvasHeight);
                        tutor.inputs.audioapi.analyserContext.fillStyle = '#F6D565';
                        tutor.inputs.audioapi.analyserContext.lineCap = 'round';
                        var multiplier = tutor.inputs.audioapi.analyserNode.frequencyBinCount / numBars;

                        // Draw rectangle for each frequency bin.
                        for (var i = 0; i < numBars; ++i) {
                            var magnitude = 0;
                            var offset = Math.floor( i * multiplier );
                            // gotta sum/average the block, or we miss narrow-bandwidth spikes
                            for (var j = 0; j< multiplier; j++){
                                magnitude += freqByteData[offset + j];
                            }
                            magnitude = scaleY * magnitude / multiplier;
                            var magnitude2 = freqByteData[i * multiplier];
                            tutor.inputs.audioapi.analyserContext.fillStyle = "hsl( " + Math.round((i*360)/numBars) + ", 100%, 50%)";
                            tutor.inputs.audioapi.analyserContext.fillRect(i * SPACING, tutor.inputs.audioapi.canvasHeight, BAR_WIDTH, -magnitude);
                        }
                    }

                    rafID = window.requestAnimationFrame( tutor.inputs.audioapi.updateAnalysers );
                }


                
                try {
                    window.AudioContext = window.AudioContext || window.webkitAudioContext;
                    tutor.inputs.audioapi.context = new AudioContext();

                    // operate animation frame
                    if (!navigator.cancelAnimationFrame){
                        navigator.cancelAnimationFrame = navigator.webkitCancelAnimationFrame || navigator.mozCancelAnimationFrame;
                    }
                    // operate animation frame
                    if (!navigator.requestAnimationFrame){
                       navigator.requestAnimationFrame = navigator.webkitRequestAnimationFrame || navigator.mozRequestAnimationFrame;
                    }

            
            
                    // get media source
                    if (!navigator.getUserMedia){
                        navigator.getUserMedia = navigator.webkitGetUserMedia || navigator.mozGetUserMedia;
                    }
                    
                    
                    // callback on audio stream created
                    // microphone -> splitter -> mono -> gain -> analyzer
                    var gotStream = function (stream) {

                        // Create AudioNode from the stream.
                        tutor.inputs.audioapi.userSourceNode = tutor.inputs.audioapi.context.createMediaStreamSource(stream);

                        // create mono channel
                        var splitter = tutor.inputs.audioapi.context.createChannelSplitter(2);
                        tutor.inputs.audioapi.userSourceNode.connect( splitter );
                        
                        
                        // on-channel sound, mono
                        tutor.inputs.audioapi.monoSoundSourceNode = tutor.inputs.audioapi.context.createChannelMerger(2);
                        splitter.connect( tutor.inputs.audioapi.monoSoundSourceNode, 0, 0 );
                        splitter.connect( tutor.inputs.audioapi.monoSoundSourceNode, 0, 1 );

                        // Gain (Усилитель)
                        tutor.inputs.audioapi.audioGain = tutor.inputs.audioapi.context.createGain();
                        // source           destination
                        tutor.inputs.audioapi.monoSoundSourceNode.connect(tutor.inputs.audioapi.audioGain);
                        
                        // create audio analyzer
                        tutor.inputs.audioapi.analyserNode = tutor.inputs.audioapi.context.createAnalyser();
                        tutor.inputs.audioapi.analyserNode.fftSize = 128;
                        tutor.inputs.audioapi.audioGain.connect( tutor.inputs.audioapi.analyserNode );


                        tutor.inputs.audioapi.audioGain.connect(tutor.inputs.audioapi.context.destination);


                        tutor.inputs.audioapi.updateAnalysers();

                    }
                    
                    
                    navigator.getUserMedia(
                    // options
                    {
                        "audio": {
                            "mandatory": {
                                "googEchoCancellation": "false",
                                "googAutoGainControl": "false",
                                "googNoiseSuppression": "false",
                                "googHighpassFilter": "false"
                            },
                        "optional": []
                        }
                    }, 
                    // on stream created
                    gotStream,
                    // on error
                    function(e) {
                        alert('Error getting audio');
                        console.log(e);
                    });
                }catch(e){
                   alert('Opps.. Your browser do not support audio API');
                }
            });

    
        </script>
    </body>
</html>